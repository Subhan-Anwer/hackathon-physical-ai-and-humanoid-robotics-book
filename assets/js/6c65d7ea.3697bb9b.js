"use strict";(globalThis.webpackChunksite=globalThis.webpackChunksite||[]).push([[340],{8453(e,n,t){t.d(n,{R:()=>r,x:()=>o});var i=t(6540);const s={},a=i.createContext(s);function r(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:n},e.children)}},9458(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module-2-digital-twin/labs/lab-4-unity-high-fidelity-simulation","title":"Lab 4: Unity High-Fidelity Simulation","description":"Overview","source":"@site/docs/module-2-digital-twin/labs/lab-4-unity-high-fidelity-simulation.md","sourceDirName":"module-2-digital-twin/labs","slug":"/module-2-digital-twin/labs/lab-4-unity-high-fidelity-simulation","permalink":"/hackathon-physical-ai-and-humanoid-robotics-book/docs/module-2-digital-twin/labs/lab-4-unity-high-fidelity-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/subhan-anwer/hackathon-physical-ai-and-humanoid-robotics-book/docs/module-2-digital-twin/labs/lab-4-unity-high-fidelity-simulation.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Lab 4: Unity High-Fidelity Simulation","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Lab 3: Robot Modeling with URDF","permalink":"/hackathon-physical-ai-and-humanoid-robotics-book/docs/module-2-digital-twin/labs/lab-3-robot-modeling-with-urdf"},"next":{"title":"Chapter 1: NVIDIA Isaac Sim Fundamentals","permalink":"/hackathon-physical-ai-and-humanoid-robotics-book/docs/module-3-ai-robot-brain/chapter-1"}}');var s=t(4848),a=t(8453);const r={title:"Lab 4: Unity High-Fidelity Simulation",sidebar_position:4},o="Lab 4: Unity High-Fidelity Simulation",l={},d=[{value:"Overview",id:"overview",level:2},{value:"Objectives",id:"objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Lab Setup",id:"lab-setup",level:2},{value:"Implementation Steps",id:"implementation-steps",level:2},{value:"Step 1: Install Unity Robotics Hub",id:"step-1-install-unity-robotics-hub",level:3},{value:"Step 2: Basic ROS 2 Connection Setup",id:"step-2-basic-ros-2-connection-setup",level:3},{value:"Step 3: Create Photorealistic Environments",id:"step-3-create-photorealistic-environments",level:3},{value:"Step 4: Implement Advanced Sensor Simulation",id:"step-4-implement-advanced-sensor-simulation",level:3},{value:"Step 5: Create User Interface for Robot Control",id:"step-5-create-user-interface-for-robot-control",level:3},{value:"Step 6: Scene Setup and Testing",id:"step-6-scene-setup-and-testing",level:3},{value:"Step 7: Testing with ROS 2",id:"step-7-testing-with-ros-2",level:3},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"What You Learned",id:"what-you-learned",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"lab-4-unity-high-fidelity-simulation",children:"Lab 4: Unity High-Fidelity Simulation"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This lab focuses on creating photorealistic simulation environments in Unity with advanced sensor simulation and user interfaces for robot teleoperation. You will set up Unity with ROS 2 integration and implement high-fidelity sensor systems."}),"\n",(0,s.jsx)(n.h2,{id:"objectives",children:"Objectives"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Set up Unity with ROS 2 integration"}),"\n",(0,s.jsx)(n.li,{children:"Create photorealistic indoor/outdoor environments"}),"\n",(0,s.jsx)(n.li,{children:"Implement advanced sensor simulation in Unity"}),"\n",(0,s.jsx)(n.li,{children:"Build user interfaces for robot teleoperation"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Unity 2021.3 LTS or later installed"}),"\n",(0,s.jsx)(n.li,{children:"ROS 2 installation (Humble Hawksbill or later)"}),"\n",(0,s.jsx)(n.li,{children:"Unity Robotics Hub package"}),"\n",(0,s.jsx)(n.li,{children:"Basic C# programming knowledge"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"lab-setup",children:"Lab Setup"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Install Unity 2021.3 LTS or later"}),"\n",(0,s.jsx)(n.li,{children:"Import Unity Robotics Hub packages"}),"\n",(0,s.jsx)(n.li,{children:"Set up ROS 2 bridge for communication"}),"\n",(0,s.jsx)(n.li,{children:"Create a new Unity project for robotics simulation"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,s.jsx)(n.h3,{id:"step-1-install-unity-robotics-hub",children:"Step 1: Install Unity Robotics Hub"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Open Unity Hub and create a new 3D project"}),"\n",(0,s.jsx)(n.li,{children:"Open the Package Manager (Window > Package Manager)"}),"\n",(0,s.jsxs)(n.li,{children:["Add the Unity Robotics packages:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Unity ROS TCP Connector"}),"\n",(0,s.jsx)(n.li,{children:"Unity URDF Importer (optional)"}),"\n",(0,s.jsx)(n.li,{children:"Unity Robotics Tools"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"step-2-basic-ros-2-connection-setup",children:"Step 2: Basic ROS 2 Connection Setup"}),"\n",(0,s.jsx)(n.p,{children:"Create a basic connection script to establish communication with ROS 2:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'using System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Geometry;\nusing RosMessageTypes.Std;\n\npublic class ROSConnectionTest : MonoBehaviour\n{\n    ROSConnection ros;\n    public string rosIPAddress = "127.0.0.1";\n    public int rosPort = 10000;\n\n    void Start()\n    {\n        // Get the ROS connection object\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Initialize(rosIPAddress, rosPort);\n\n        // Start sending messages on a regular interval\n        InvokeRepeating("SendTwistMessage", 0.0f, 0.5f);\n    }\n\n    void SendTwistMessage()\n    {\n        // Create a Twist message\n        var twist = new TwistMsg();\n        twist.linear = new Vector3Msg(0.1f, 0, 0);  // Move forward\n        twist.angular = new Vector3Msg(0, 0, 0.2f); // Rotate\n\n        // Send the message to the \'cmd_vel\' topic\n        ros.Send("cmd_vel", twist);\n    }\n\n    void OnApplicationQuit()\n    {\n        ros.Disconnect();\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-3-create-photorealistic-environments",children:"Step 3: Create Photorealistic Environments"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Using Built-in Render Pipeline:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Create a new scene"}),"\n",(0,s.jsx)(n.li,{children:"Add a Terrain object (GameObject > 3D Object > Terrain)"}),"\n",(0,s.jsx)(n.li,{children:"Sculpt terrain using terrain tools"}),"\n",(0,s.jsx)(n.li,{children:'Add textures using the "Paint Texture" tool'}),"\n",(0,s.jsx)(n.li,{children:'Add trees and details using the "Paint Trees" and "Paint Details" tools'}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Enhanced Lighting Setup:"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\n\npublic class EnvironmentLighting : MonoBehaviour\n{\n    public Light sunLight;\n    public float dayNightCycleSpeed = 0.5f;\n    private float timeOfDay = 0.5f; // 0.5 = noon, 0 = midnight\n\n    void Start()\n    {\n        if (sunLight == null)\n        {\n            sunLight = FindObjectOfType<Light>();\n            if (sunLight != null && sunLight.type == LightType.Directional)\n            {\n                // Found the directional light (sun)\n            }\n            else\n            {\n                // Create a sun light if none exists\n                GameObject sunObj = new GameObject("Sun");\n                sunLight = sunObj.AddComponent<Light>();\n                sunLight.type = LightType.Directional;\n                sunLight.color = Color.white;\n                sunLight.intensity = 1.0f;\n            }\n        }\n    }\n\n    void Update()\n    {\n        // Update time of day\n        timeOfDay += Time.deltaTime * dayNightCycleSpeed * 0.01f;\n        if (timeOfDay >= 1.0f) timeOfDay = 0.0f;\n\n        // Update sun position based on time of day\n        float sunAngle = timeOfDay * 360f - 90f; // Start at dawn (sunrise)\n        sunLight.transform.rotation = Quaternion.Euler(sunAngle, 10f, 0f);\n\n        // Adjust light intensity and color based on sun position\n        float intensityMultiplier = Mathf.Clamp01(Mathf.Sin(timeOfDay * Mathf.PI));\n        sunLight.intensity = 1.0f * intensityMultiplier;\n\n        // Change color from dawn/dusk (orange) to midday (white)\n        float colorBlend = Mathf.Clamp01(Mathf.Abs(timeOfDay - 0.5f) * 2f);\n        sunLight.color = Color.Lerp(new Color(1f, 0.7f, 0.4f), Color.white, 1f - colorBlend);\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-4-implement-advanced-sensor-simulation",children:"Step 4: Implement Advanced Sensor Simulation"}),"\n",(0,s.jsx)(n.p,{children:"Create scripts for different sensor types:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.strong,{children:"RGB Camera Sensor:"})}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\n\npublic class RGBCameraSensor : MonoBehaviour\n{\n    ROSConnection ros;\n    public string topicName = "camera/image_raw";\n    public int width = 640;\n    public int height = 480;\n    public float fieldOfView = 60f;\n\n    Camera cam;\n    RenderTexture renderTexture;\n    Texture2D texture2D;\n    byte[] rawImage;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n\n        // Setup camera\n        cam = GetComponent<Camera>();\n        cam.fieldOfView = fieldOfView;\n\n        // Create render texture\n        renderTexture = new RenderTexture(width, height, 24);\n        cam.targetTexture = renderTexture;\n\n        // Create texture2D for reading pixels\n        texture2D = new Texture2D(width, height, TextureFormat.RGB24, false);\n\n        // Start capturing at a regular interval\n        InvokeRepeating("CaptureAndSendImage", 0.0f, 0.1f); // 10 FPS\n    }\n\n    void CaptureAndSendImage()\n    {\n        // Set the active render texture\n        RenderTexture.active = renderTexture;\n\n        // Read pixels from the render texture\n        texture2D.ReadPixels(new Rect(0, 0, width, height), 0, 0);\n        texture2D.Apply();\n\n        // Get raw image bytes\n        rawImage = texture2D.EncodeToJPG();\n\n        // Create ROS Image message\n        ImageMsg imageMsg = new ImageMsg();\n        imageMsg.header = new std_msgs.HeaderMsg(0, new builtin_interfaces.TimeMsg(), topicName);\n        imageMsg.height = (uint)height;\n        imageMsg.width = (uint)width;\n        imageMsg.encoding = "rgb8";\n        imageMsg.is_bigendian = 0;\n        imageMsg.step = (uint)(width * 3); // 3 bytes per pixel (RGB)\n        imageMsg.data = rawImage;\n\n        // Send the image message\n        ros.Send(topicName, imageMsg);\n    }\n}\n'})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.strong,{children:"Depth Camera Sensor:"})}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class DepthCameraSensor : MonoBehaviour\n{\n    ROSConnection ros;\n    public string topicName = "depth_camera/image_raw";\n    public int width = 320;\n    public int height = 240;\n    public float fieldOfView = 60f;\n    public float maxRange = 10.0f;\n\n    Camera cam;\n    RenderTexture depthTexture;\n    Texture2D texture2D;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n\n        // Setup camera for depth rendering\n        cam = GetComponent<Camera>();\n        cam.fieldOfView = fieldOfView;\n        cam.depthTextureMode = DepthTextureMode.Depth;\n\n        // Create render texture for depth\n        depthTexture = new RenderTexture(width, height, 24, RenderTextureFormat.RFloat);\n        cam.targetTexture = depthTexture;\n\n        // Create texture2D for reading depth data\n        texture2D = new Texture2D(width, height, TextureFormat.RFloat, false);\n\n        // Start capturing at a regular interval\n        InvokeRepeating("CaptureAndSendDepth", 0.0f, 0.1f); // 10 FPS\n    }\n\n    void CaptureAndSendDepth()\n    {\n        // Set the active render texture\n        RenderTexture.active = depthTexture;\n\n        // Read pixels from the depth texture\n        texture2D.ReadPixels(new Rect(0, 0, width, height), 0, 0);\n        texture2D.Apply();\n\n        // Get raw depth data\n        Color[] depthColors = texture2D.GetPixels();\n        float[] depthValues = new float[width * height];\n\n        for (int i = 0; i < depthValues.Length; i++)\n        {\n            // Convert from 0-1 range to actual distance\n            depthValues[i] = depthColors[i].r * maxRange;\n        }\n\n        // Create ROS Image message for depth\n        ImageMsg depthMsg = new ImageMsg();\n        depthMsg.header = new std_msgs.HeaderMsg(0, new builtin_interfaces.TimeMsg(), topicName);\n        depthMsg.height = (uint)height;\n        depthMsg.width = (uint)width;\n        depthMsg.encoding = "32FC1"; // 32-bit float, single channel\n        depthMsg.is_bigendian = 0;\n        depthMsg.step = (uint)(width * sizeof(float)); // 4 bytes per float\n\n        // Convert float array to byte array\n        byte[] depthBytes = new byte[depthValues.Length * sizeof(float)];\n        System.Buffer.BlockCopy(depthValues, 0, depthBytes, 0, depthBytes.Length);\n        depthMsg.data = depthBytes;\n\n        // Send the depth message\n        ros.Send(topicName, depthMsg);\n    }\n}\n'})}),"\n",(0,s.jsxs)(n.ol,{start:"3",children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.strong,{children:"LIDAR Sensor Simulation:"})}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class LIDARSensor : MonoBehaviour\n{\n    ROSConnection ros;\n    public string topicName = "scan";\n    public int numberOfRays = 360;\n    public float minAngle = -Mathf.PI;\n    public float maxAngle = Mathf.PI;\n    public float maxRange = 10.0f;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        InvokeRepeating("SendLIDARData", 0.0f, 0.1f); // 10 FPS\n    }\n\n    void SendLIDARData()\n    {\n        // Perform raycasts to simulate LIDAR\n        float[] ranges = new float[numberOfRays];\n        float angleStep = (maxAngle - minAngle) / numberOfRays;\n\n        for (int i = 0; i < numberOfRays; i++)\n        {\n            float angle = minAngle + (i * angleStep);\n            Vector3 direction = new Vector3(Mathf.Cos(angle), 0, Mathf.Sin(angle));\n            direction = transform.TransformDirection(direction);\n\n            RaycastHit hit;\n            if (Physics.Raycast(transform.position, direction, out hit, maxRange))\n            {\n                ranges[i] = hit.distance;\n            }\n            else\n            {\n                ranges[i] = maxRange; // No obstacle detected within range\n            }\n        }\n\n        // Create LaserScan message\n        LaserScanMsg scanMsg = new LaserScanMsg();\n        scanMsg.header = new std_msgs.HeaderMsg(0, new builtin_interfaces.TimeMsg(), "lidar_link");\n        scanMsg.angle_min = minAngle;\n        scanMsg.angle_max = maxAngle;\n        scanMsg.angle_increment = angleStep;\n        scanMsg.time_increment = 0.0f; // For simulated data\n        scanMsg.scan_time = 0.1f; // 10Hz\n        scanMsg.range_min = 0.1f;\n        scanMsg.range_max = maxRange;\n        scanMsg.ranges = ranges;\n        scanMsg.intensities = new float[numberOfRays]; // Initialize with zeros\n\n        // Send the LIDAR message\n        ros.Send(topicName, scanMsg);\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-5-create-user-interface-for-robot-control",children:"Step 5: Create User Interface for Robot Control"}),"\n",(0,s.jsx)(n.p,{children:"Create a comprehensive UI system for robot teleoperation:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.strong,{children:"Main Control Panel Script:"})}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.UI;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Geometry;\n\npublic class RobotControlPanel : MonoBehaviour\n{\n    ROSConnection ros;\n    public Slider linearVelocitySlider;\n    public Slider angularVelocitySlider;\n    public Button moveButton;\n    public Button stopButton;\n    public Text statusText;\n    public Text positionText;\n\n    // Robot position tracking\n    private Vector3 robotPosition = Vector3.zero;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n\n        // Setup UI event listeners\n        moveButton.onClick.AddListener(SendVelocityCommand);\n        stopButton.onClick.AddListener(SendStopCommand);\n        linearVelocitySlider.onValueChanged.AddListener(OnLinearVelocityChanged);\n        angularVelocitySlider.onValueChanged.AddListener(OnAngularVelocityChanged);\n\n        // Initialize UI\n        UpdateUI();\n    }\n\n    void UpdateUI()\n    {\n        statusText.text = "Connected to ROS";\n        positionText.text = $"Position: {robotPosition.x:F2}, {robotPosition.y:F2}, {robotPosition.z:F2}";\n    }\n\n    void SendVelocityCommand()\n    {\n        var twistMsg = new TwistMsg();\n        twistMsg.linear = new Vector3Msg(linearVelocitySlider.value, 0, 0);\n        twistMsg.angular = new Vector3Msg(0, 0, angularVelocitySlider.value);\n\n        ros.Send("cmd_vel", twistMsg);\n        statusText.text = "Command sent: Linear=" + linearVelocitySlider.value + ", Angular=" + angularVelocitySlider.value;\n    }\n\n    void SendStopCommand()\n    {\n        var twistMsg = new TwistMsg();\n        twistMsg.linear = new Vector3Msg(0, 0, 0);\n        twistMsg.angular = new Vector3Msg(0, 0, 0);\n\n        ros.Send("cmd_vel", twistMsg);\n        statusText.text = "Stop command sent";\n    }\n\n    void OnLinearVelocityChanged(float value)\n    {\n        // Update UI feedback\n    }\n\n    void OnAngularVelocityChanged(float value)\n    {\n        // Update UI feedback\n    }\n}\n'})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.strong,{children:"Sensor Visualization Panel:"})}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.UI;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class SensorVisualization : MonoBehaviour\n{\n    public RawImage cameraFeedImage;\n    public Texture2D defaultTexture;\n    public Image lidarVisualization;\n    public Text sensorStatusText;\n\n    void Start()\n    {\n        // Initialize camera feed image\n        if (cameraFeedImage != null)\n        {\n            cameraFeedImage.texture = defaultTexture;\n        }\n\n        // Subscribe to camera topic\n        ROSConnection.GetOrCreateInstance().Subscribe<ImageMsg>("camera/image_raw", UpdateCameraFeed);\n\n        sensorStatusText.text = "Sensors initialized";\n    }\n\n    void UpdateCameraFeed(ImageMsg imageMsg)\n    {\n        if (cameraFeedImage != null)\n        {\n            // Create texture from image data\n            Texture2D texture = new Texture2D((int)imageMsg.width, (int)imageMsg.height, TextureFormat.RGB24, false);\n\n            // Note: This is a simplified approach; in practice, you\'d need to properly decode the image data\n            // based on the encoding format specified in the message\n            if (imageMsg.encoding == "rgb8")\n            {\n                texture.LoadRawTextureData(imageMsg.data);\n                texture.Apply();\n                cameraFeedImage.texture = texture;\n            }\n        }\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-6-scene-setup-and-testing",children:"Step 6: Scene Setup and Testing"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Create a new Unity scene"}),"\n",(0,s.jsx)(n.li,{children:"Add a robot model (or simple geometric shapes to represent the robot)"}),"\n",(0,s.jsx)(n.li,{children:"Attach the sensor scripts to appropriate GameObjects"}),"\n",(0,s.jsx)(n.li,{children:"Add the control panel UI to the scene"}),"\n",(0,s.jsx)(n.li,{children:"Configure the Canvas and UI elements"}),"\n",(0,s.jsx)(n.li,{children:"Test the connection with ROS 2"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"step-7-testing-with-ros-2",children:"Step 7: Testing with ROS 2"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Start ROS 2 daemon:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"source /opt/ros/humble/setup.bash\nros2 daemon start\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsx)(n.li,{children:"Create a simple ROS 2 node to receive commands:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\n\nclass RobotCommandReceiver(Node):\n    def __init__(self):\n        super().__init__('robot_command_receiver')\n        self.subscription = self.create_subscription(\n            Twist,\n            'cmd_vel',\n            self.listener_callback,\n            10)\n        self.get_logger().info('Robot command receiver started')\n\n    def listener_callback(self, msg):\n        self.get_logger().info(f'Received cmd_vel: linear={msg.linear.x}, angular={msg.angular.z}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = RobotCommandReceiver()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"What are the advantages of using Unity for high-fidelity robotics simulation compared to Gazebo?"}),"\n",(0,s.jsx)(n.li,{children:"How does the Unity-ROS 2 bridge handle data transmission between the two systems?"}),"\n",(0,s.jsx)(n.li,{children:"What are the computational trade-offs when using photorealistic rendering in robotics simulation?"}),"\n",(0,s.jsx)(n.li,{children:"How would you implement collision detection between the Unity robot and real-world objects?"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"what-you-learned",children:"What You Learned"}),"\n",(0,s.jsx)(n.p,{children:"In this lab, you learned how to set up Unity with ROS 2 integration, create photorealistic environments, implement advanced sensor simulation, and build user interfaces for robot teleoperation. You gained hands-on experience with Unity's capabilities for high-fidelity robotics simulation and learned how to integrate various sensor systems into your virtual environment."})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);